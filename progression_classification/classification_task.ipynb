{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, label_binarize, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score, make_scorer\n",
    "from sklearn.utils import resample\n",
    "from tqdm.notebook import tqdm, tnrange\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.distributions as dist\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "import gpytorch\n",
    "\n",
    "from classification_utils import *\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_state = 1 # random seed used in every place which take a seed as input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label categories:\n",
    "* 0 corresponds to 'No trend' \n",
    "* 1 corresponds to 'Decreasing trend' \n",
    "* 2 corresponds to 'Increasing trend'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nick_\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\Users\\nick_\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('cross_sectional_data.csv', index_col=[0])\n",
    "X , y = encode(data.drop(columns=['ID', 'Labels'])) , data['Labels'].to_numpy()\n",
    "# Fix missing values\n",
    "col_list = list(X.columns.values)\n",
    "X = X.reindex(columns=col_list).fillna(0)\n",
    "X = X[col_list]\n",
    "X_numeric = X.iloc[: , :8]\n",
    "\n",
    "# Standardize numeric features\n",
    "scaler = StandardScaler()\n",
    "X_numeric = scaler.fit_transform(X_numeric)\n",
    "X_numeric = pd.DataFrame(X_numeric, columns=encode(data.drop(columns=['ID', 'Labels'])).columns.values[:8])\n",
    "X = pd.concat([X_numeric, X.iloc[:, 8:]], axis=1)\n",
    "X = X.drop(columns=['r2', 'slope']) # remove these two features since they won't be available in case of model deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training and test sets\n",
    "\n",
    "We then fine-tune the models using sklearn functionality on the training set, so for now we don't create any validation sets.\n",
    "\n",
    "We are also careful to keep the proportions of labels in the training, testing and validation sets the same. This is quite important since we are dealing with imbalanced labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state = rand_state, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01}\n",
      "MCC on test set using Logistic regression: 0.195\n",
      "Accuracy on test set using Logistic regression: 0.723\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=rand_state) # can use skf.split(X_train, y_train) to get the indices of the folding (useful when working with BNN and GP)\n",
    "\n",
    "\n",
    "lr_C_vals = [0.01, 0.1, 0.5, 1, 3, 5, 10, 20, 30, 40, 50, 70, 100, 200, 500, 1000, 2000, 5000, 10_000, 100_000] # L2-regularisation values\n",
    "log_reg = LogisticRegression(penalty='l2', max_iter=10_000, multi_class='multinomial')\n",
    "log_reg_grid = {'C' : lr_C_vals}\n",
    "# Tune model\n",
    "tuned_log_reg , log_reg_test_mcc = tune_model_and_get_test_mcc(X, y, log_reg, rand_state=rand_state, hyperparam_grid=log_reg_grid, test_size=0.2, print_best_params=True)\n",
    "# Evaluate on test set\n",
    "print(f'MCC on test set using Logistic regression: {log_reg_test_mcc :.3f}')\n",
    "print(f'Accuracy on test set using Logistic regression: {accuracy_score(y_test , tuned_log_reg.predict(X_test)) :.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 40, 'gamma': 0.01}\n",
      "MCC on test set using SVC: 0.102\n",
      "Accuracy on test set using SVC: 0.711\n"
     ]
    }
   ],
   "source": [
    "svm_C_vals = [0.01, 0.1, 0.5, 1, 3, 5, 10, 20, 30, 40, 50, 70, 100, 200, 500, 1000, 2000, 5000, 10_000, 100_000] # regularisation strength constant\n",
    "rbf_gamma_vals = [0.0001, 0.001, 0.005, 0.01, 0.1, 0.2, 0.5, 0.8, 1, 2, 3, 5, 10, 15, 30, 40, 50, 100, 200, 500, 1000, 10_000]\n",
    "svc_grid = {'C' : svm_C_vals, 'gamma' : rbf_gamma_vals}\n",
    "svc = SVC(kernel='rbf')\n",
    "\n",
    "# Tune model\n",
    "tuned_svc , svc_test_mcc = tune_model_and_get_test_mcc(X, y, svc, rand_state=rand_state, hyperparam_grid=svc_grid, test_size=0.2, print_best_params=True)\n",
    "# Evaluate on test set\n",
    "print(f'MCC on test set using SVC: {svc_test_mcc :.3f}')\n",
    "print(f'Accuracy on test set using SVC: {accuracy_score(y_test , tuned_svc.predict(X_test)) :.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest classifier (tuning takes 80 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 20, 'max_features': 'auto', 'min_samples_split': 10, 'n_estimators': 300}\n",
      "{'max_depth': 10, 'max_features': 'auto', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "{'max_depth': 10, 'max_features': 'auto', 'min_samples_split': 10, 'n_estimators': 500}\n",
      "{'max_depth': 30, 'max_features': 'auto', 'min_samples_split': 10, 'n_estimators': 500}\n",
      "{'max_depth': 10, 'max_features': 'auto', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "0.7190082644628099\n",
      "0.009778644269586157\n",
      "\n",
      "\n",
      "0.18930431260372385\n",
      "0.04568232545691486\n"
     ]
    }
   ],
   "source": [
    "acc_list , mcc_list = [] , []\n",
    "\n",
    "for z in range(1, 6):\n",
    "\n",
    "    test_size = 0.20\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state = z, stratify = y)\n",
    "\n",
    "    rf_n_est = [100, 200, 300, 400, 500, 1000, 1500, 2000, 5000, 10_000]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 5, 10]\n",
    "\n",
    "    rf_grid = {'n_estimators' : rf_n_est, 'max_depth' : max_depth, 'max_features' : max_features, 'min_samples_split' : min_samples_split}\n",
    "    rf = RandomForestClassifier(n_estimators=100, criterion='gini', random_state=z, n_jobs=-1)\n",
    "\n",
    "    # Tune model\n",
    "    tuned_rf , rf_test_mcc = tune_model_and_get_test_mcc(X, y, rf, rand_state=z, hyperparam_grid=rf_grid, test_size=0.2, print_best_params=True)\n",
    "    # Evaluate on test set\n",
    "    #print(f'MCC on test set using RF: {rf_test_mcc :.3f}')\n",
    "    #print(f'Accuracy on test set using RF: {accuracy_score(y_test , tuned_rf.predict(X_test)) :.3f}')\n",
    "\n",
    "    acc_list.append(accuracy_score(y_test , tuned_rf.predict(X_test)))\n",
    "    mcc_list.append(rf_test_mcc)\n",
    "\n",
    "print(np.mean(acc_list))\n",
    "print(np.std(acc_list))\n",
    "print('\\n')\n",
    "print(np.mean(mcc_list))\n",
    "print(np.std(mcc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 30, 'max_features': 'auto', 'min_samples_split': 10, 'n_estimators': 400}\n",
      "MCC on test set using RF: 0.204\n",
      "Accuracy on test set using RF: 0.843\n"
     ]
    }
   ],
   "source": [
    "rf_n_est = [100, 200, 300, 400, 500, 1000, 1500, 2000, 5000, 10_000]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "rf_grid = {'n_estimators' : rf_n_est, 'max_depth' : max_depth, 'max_features' : max_features, 'min_samples_split' : min_samples_split}\n",
    "rf = RandomForestClassifier(n_estimators=100, criterion='gini', random_state=1, n_jobs=-1)\n",
    "\n",
    "# Tune model\n",
    "tuned_rf , rf_test_mcc = tune_model_and_get_test_mcc(X, y, rf, rand_state=rand_state, hyperparam_grid=rf_grid, test_size=0.2, print_best_params=True)\n",
    "# Evaluate on test set\n",
    "print(f'MCC on test set using RF: {rf_test_mcc :.3f}')\n",
    "print(f'Accuracy on test set using RF: {accuracy_score(y_test , tuned_rf.predict(X_test)) :.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dc1a1fe9425be4de01979652791da0a8b93aa88df29b2975e2e67ada710aecb7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
